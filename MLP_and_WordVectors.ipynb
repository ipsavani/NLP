{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009434c7",
   "metadata": {},
   "source": [
    "# MLP and Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8258b5",
   "metadata": {},
   "source": [
    "1. Implement MLP.\n",
    "2. Implement Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "218b9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "#                                                             #\n",
    "#    Run this cell to make sure all packages are installed.   #\n",
    "#                                                             #\n",
    "###############################################################\n",
    "\n",
    "# !pip install numpy pandas scikit-learn tqdm matplotlib\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4cb51",
   "metadata": {},
   "source": [
    "## 1. MLP\n",
    "1. Data Processing \n",
    "2. MLP\n",
    "3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96da71",
   "metadata": {},
   "source": [
    "### 1.1 Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb178810",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1264b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# training data\n",
    "train_df = pd.read_csv('./data/train.csv', header=None)\n",
    "train_df.columns = ['label', 'title', 'text']\n",
    "\n",
    "# test data\n",
    "test_df = pd.read_csv('./data/test.csv', header=None)\n",
    "test_df.columns = ['label', 'title', 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d60be8",
   "metadata": {},
   "source": [
    "####  Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e00d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "class Preprocesser(object):\n",
    "    def __init__(self, punctuation=True, url=True, number=True):\n",
    "        self.punctuation = punctuation\n",
    "        self.url = url\n",
    "        self.number = number\n",
    "    \n",
    "    def apply(self, text):\n",
    "        \n",
    "        text = self._lowercase(text)\n",
    "        \n",
    "        if self.url:\n",
    "            text = self._remove_url(text)\n",
    "            \n",
    "        if self.punctuation:\n",
    "            text = self._remove_punctuation(text)\n",
    "            \n",
    "        if self.number:\n",
    "            text = self._remove_number(text)\n",
    "        \n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "            \n",
    "        return text\n",
    "    \n",
    "        \n",
    "    def _remove_punctuation(self, text):\n",
    "        ''' Please fill this function to remove all the punctuations in the text\n",
    "        '''\n",
    "        text = text.translate(str.maketrans('','', string.punctuation))\n",
    "        return text\n",
    "    \n",
    "    def _remove_url(self, text):\n",
    "        ''' Please fill this function to remove all the urls in the text\n",
    "        '''\n",
    "        text = re.sub(r'\\S*https?:\\S*','',text)\n",
    " \n",
    "        return text\n",
    "    \n",
    "    def _remove_number(self, text):\n",
    "        ''' Please fill this function to remove all the numbers in the text\n",
    "        '''\n",
    "        text = text.translate(str.maketrans('','', string.digits))\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _lowercase(self, text):\n",
    "        ''' Please fill this function to lowercase the text\n",
    "        '''\n",
    "        text = text.lower()\n",
    "        \n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924e1fea",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cf6d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize(text):\n",
    "    ''' Please fill this function to tokenize text.\n",
    "            1. Tokenize the text.\n",
    "            2. Remove stop words.\n",
    "            3. Optional: lemmatize words accordingly.\n",
    "    '''\n",
    "    \n",
    "    stop_words = nlp.Defaults.stop_words\n",
    "    tokens = text.strip().split()\n",
    "#     tokens = nlp(text)\n",
    "#     tokens = re.split(r\"\\W+\", text.strip())\n",
    "\n",
    "    tokens = [token for token in tokens if not token in stop_words]\n",
    "\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91bec82",
   "metadata": {},
   "source": [
    "#### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "375a7054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training set: 96000\n",
      "The size of validation set: 24000\n",
      "The size of testing set: 7600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_train = train_df['text'].values.astype(str)\n",
    "label_train = train_df['label'].values.astype(int) - 1 # -1 because labels start from 1\n",
    "\n",
    "text_test = test_df['text'].values.astype(str)\n",
    "label_test = test_df['label'].values.astype(int) - 1 # -1 because labels start from 1\n",
    "\n",
    "\n",
    "text_train, text_valid, label_train, label_valid = train_test_split(text_train, label_train, test_size=0.2)\n",
    "\n",
    "\n",
    "print('The size of training set:', text_train.shape[0])\n",
    "print('The size of validation set:', text_valid.shape[0])\n",
    "print('The size of testing set:', text_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53246242",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02582f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class TfIdfExtractor(object):\n",
    "    \n",
    "    def __init__(self, vocab_size=None):\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        self.vocab = defaultdict(lambda: 0)\n",
    "        self.word2idx = {}\n",
    "        self.df = defaultdict(lambda: 0)\n",
    "        self.num_doc = 0\n",
    "        \n",
    "        self.processer = Preprocesser()\n",
    "        \n",
    "        \n",
    "    def fit(self, texts):\n",
    "        ''' \n",
    "                1. Construct the vocabulary (self.vocab).\n",
    "                2. Construct the document frequency dictionary (self.df).\n",
    "                3. Sort the vocabulary based on the frequency (self.vocab).\n",
    "            Input:\n",
    "                texts: a list of text (training set)\n",
    "            Output:\n",
    "                None\n",
    "        '''\n",
    "\n",
    "        self.num_doc = len(texts)\n",
    "        \n",
    "        for text in tqdm(texts, desc='fitting text'):\n",
    "            clean_text = self.processer.apply(text)\n",
    "            tokens = tokenize(clean_text)\n",
    "            \n",
    "            # add unique words in vocab\n",
    "            self.vocab.update({token:0 for token in tokens})\n",
    "            # get frequency of words in each document\n",
    "            self.df.update({token:self.df[token]+1 for token in set(tokens)})\n",
    "\n",
    "        # sort vocabulary based on document frequency\n",
    "        self.vocab = dict(sorted(self.vocab.items(), key=lambda x: self.df[x[0]], reverse=True))\n",
    "                \n",
    "        if self.vocab_size is not None:\n",
    "            self.vocab = {key: self.vocab[key] for key in list(self.vocab.keys())[:self.vocab_size]}\n",
    "        \n",
    "        self.word2idx = {key: idx for idx, key in enumerate(self.vocab.keys())}\n",
    "\n",
    "\n",
    "    def transform(self, texts):\n",
    "        ''' \n",
    "            Input:\n",
    "                texts: a list of text.\n",
    "            Ouput:\n",
    "                a N-d matrix (Tf-Idf) \n",
    "        '''\n",
    "        tfidf = np.zeros((len(texts), len(self.vocab)))\n",
    "        \n",
    "        for i, text in tqdm(enumerate(texts), desc='transforming', total=len(texts)):\n",
    "            clean_text = self.processer.apply(text)\n",
    "            tokens = tokenize(clean_text)\n",
    "            \n",
    "            # calculate term frequncy \n",
    "            tf = [tokens.count(word)/len(tokens) for idx,word in enumerate(self.word2idx.keys())]\n",
    "            idf = [np.log((self.num_doc)/(self.df[word]+1)) for idx,word in enumerate(self.word2idx.keys())]\n",
    "            # tfidf[i] = tf*idf\n",
    "            tfidf[i] = np.array([x*y for x,y in zip(tf,idf)])\n",
    "\n",
    "        \n",
    "        return tfidf\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea3b1d",
   "metadata": {},
   "source": [
    "#### Obtain the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4edb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed25604f9b0e4946b29beb38d168fc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "fitting text:   0%|          | 0/96000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec839b7f4bb94828996684e612f20ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transforming:   0%|          | 0/96000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed23315f59948289c1524f19d4b868e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transforming:   0%|          | 0/24000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40eaa41b03814e72ab7e7519c64b301d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transforming:   0%|          | 0/7600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of training set: (96000, 4000)\n",
      "The size of validation set: (24000, 4000)\n",
      "The size of test set: (7600, 4000)\n"
     ]
    }
   ],
   "source": [
    "# You can change this number to see the difference of the performances. (larger vocab size needs more memory)\n",
    "vocab_size = 4000\n",
    "num_class = 4\n",
    "\n",
    "extractor = TfIdfExtractor(vocab_size=vocab_size)\n",
    "extractor.fit(text_train)\n",
    "\n",
    "x_train = extractor.transform(text_train)\n",
    "x_valid = extractor.transform(text_valid)\n",
    "x_test = extractor.transform(text_test)\n",
    "\n",
    "\n",
    "# convert label to one-hot vector\n",
    "y_train = np.zeros((label_train.shape[0], num_class))\n",
    "y_train[np.arange(label_train.shape[0]), label_train] = 1\n",
    "\n",
    "y_valid = np.zeros((label_valid.shape[0], num_class))\n",
    "y_valid[np.arange(label_valid.shape[0]), label_valid] = 1\n",
    "\n",
    "y_test = np.zeros((label_test.shape[0], num_class))\n",
    "y_test[np.arange(label_test.shape[0]), label_test] = 1\n",
    "\n",
    "\n",
    "print('The size of training set:', x_train.shape)\n",
    "print('The size of validation set:', x_valid.shape)\n",
    "print('The size of test set:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e56c3",
   "metadata": {},
   "source": [
    "### 1.2 MLP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b6a93",
   "metadata": {},
   "source": [
    "#### 1.2.1 Implement MLP\n",
    "\n",
    "> $z_1 = w_1x$\n",
    "\n",
    "> $h_1 = activation(z_1)$\n",
    "\n",
    "> $z_2 = w_2 h_1$\n",
    "\n",
    "> $\\hat{y} = softmax(z_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2320e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    \n",
    "    def __init__(self, num_feature, hidden_size, num_class):\n",
    "        ''' Initialize the weight of MLP.\n",
    "            Inputs:\n",
    "                num_feature: scalar, the number of features (in this case, it is the vocab size).\n",
    "                hidden_size: scaler, the number of neurons in the hidden layer.\n",
    "                num_class: scalar, the number of classes.\n",
    "        '''\n",
    "                \n",
    "        self.w1 = np.random.rand(num_feature, hidden_size)\n",
    "        self.w2 = np.random.rand(hidden_size, num_class)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Implement the forward pass.\n",
    "            Input:\n",
    "                x: N-d matrix\n",
    "            Outputs\n",
    "                y_hat: the output of the model, N-K matrix.\n",
    "                h1: the output of the first hidden layer.\n",
    "                z1: the output of the first hidden before activation function.\n",
    "                \n",
    "                Note that the reason for return h1 and z1 is for calculating the gradient of self.w1 and self.w2.\n",
    "                Feel free to change it accordingly.\n",
    "        '''\n",
    "        \n",
    "        z1 = np.dot(x,self.w1)\n",
    "        h1 = self.activation(z1)\n",
    "        y_hat = self.softmax(np.dot(h1,self.w2)).squeeze()\n",
    "        \n",
    "        return y_hat, (h1, z1)\n",
    "    \n",
    "    \n",
    "    def backward(self, lr, x, y, y_hat, h1, z1):\n",
    "        ''' Implement back-propagation.\n",
    "            Inputs:\n",
    "                lr: learning rate.\n",
    "                x: the input, N-d matrix.\n",
    "                y_hat: the output, N-K matrix.\n",
    "                y: ground truth (N-K one-hot matrix).\n",
    "                h1: the output of the first hidden layer.\n",
    "                z1: the output of the first hidden before activation function.\n",
    "        '''\n",
    "\n",
    "        # Get the gradient of w1 and w2\n",
    "        grad_w1, grad_w2 = self.gradient(x, y, y_hat, h1, z1)\n",
    "        \n",
    "        # Gradient descent\n",
    "        self.w1 -= lr * grad_w1\n",
    "        self.w2 -= lr * grad_w2\n",
    "        \n",
    "    \n",
    "    def objective(self, y, y_hat):\n",
    "        ''' Compute the loss\n",
    "            Inputs:\n",
    "                y: N-K matrix, ground truth.\n",
    "                y_hat: N-K matrix, prediction.\n",
    "            Output:\n",
    "                loss: scalar, the loss of the model.\n",
    "        '''\n",
    "        \n",
    "        loss = 0.\n",
    "        \n",
    "        loss = -np.mean(np.sum(y * np.log(y_hat),axis=1))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def gradient(self, x, y, y_hat, h1, z1):\n",
    "        ''' Compute the gradient of self.w1 and self.w2\n",
    "            Inputs:\n",
    "                x: the input, N-d matrix.\n",
    "                y_hat: the output, N-K matrix.\n",
    "                y: ground truth (N-K one-hot matrix).\n",
    "                h1: the output of the first hidden layer.\n",
    "                z1: the output of the first hidden before activation function.\n",
    "            Outputs:\n",
    "                grad_w1: the gradient of self.w1.\n",
    "                grad_w2: the gradient of self.w2.\n",
    "        '''\n",
    "        n = x.shape[0]\n",
    "        \n",
    "        \n",
    "        grad_w1 = (1/n)*np.dot(x.T,((h1*(1 - h1))*np.dot((y_hat - y),self.w2.T)))\n",
    "        grad_w2 = (1/n)*np.dot(h1.T,(y_hat - y))\n",
    "        \n",
    "        \n",
    "        return grad_w1, grad_w2\n",
    "    \n",
    "    \n",
    "    def activation(self, x):\n",
    "        ''' Implement the Sigmoid activation function .\n",
    "            \n",
    "            Input:\n",
    "                x: N-d matrix\n",
    "            Output:\n",
    "                x: sigmoid(x) or ReLU(x)\n",
    "        '''\n",
    "        \n",
    "        # sigmoid\n",
    "        x = 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def softmax(self, x):\n",
    "        if len(x.shape) == 1:\n",
    "            x = x - np.max(x)\n",
    "            return np.exp(x) / np.sum(np.exp(x))\n",
    "        else:\n",
    "            x = x - np.max(x, axis=1).reshape(-1, 1)\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=1).reshape(-1, 1)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d3e1c4",
   "metadata": {},
   "source": [
    "#### 1.2.2 Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09e3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(model, X, y, lr, batch_size=None, num_epoch=100):\n",
    "    ''' Implement Mini-batch GD\n",
    "        Inputs:\n",
    "            X: N-d matrix\n",
    "            y: N vector\n",
    "            lr: learning rate\n",
    "            batch_size: optional, depends on if you use Mini-batch GD\n",
    "            num_epoch: the number of epochs\n",
    "        Output:\n",
    "            A list of training losses against epoch\n",
    "            A list of validation losses against epoch\n",
    "    '''\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    n, _ = X.shape\n",
    "    \n",
    "    for e in range(num_epoch):\n",
    "        train_loss = 0.\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        rand_indices = np.random.permutation(n)\n",
    "        x_rand = X[rand_indices]\n",
    "        y_rand = y[rand_indices]\n",
    "        \n",
    "        for b in tqdm(range(0, n, batch_size), f'Epoch {e+1}/{num_epoch}'):\n",
    "            x_batch = x_rand[b: b+batch_size] \n",
    "            y_batch = y_rand[b: b+batch_size]\n",
    "            \n",
    "            \n",
    "            ### Step 1, call forward function to get outputs\n",
    "            y_hat, (h1, z1) = model.forward(x_batch)\n",
    "            \n",
    "            ### Step 2, call objective function to get loss\n",
    "            loss = model.objective(y_batch, y_hat)\n",
    "            \n",
    "            ### Step 3, call backward to update the weights\n",
    "            model.backward(lr, x_batch, y_batch, y_hat, h1, z1)\n",
    "            \n",
    "            \n",
    "            losses.append(loss)\n",
    "        \n",
    "        train_loss = np.mean(losses)\n",
    "        \n",
    "        \n",
    "        y_hat, _ = model.forward(x_valid)\n",
    "        valid_loss = model.objective(y_valid, y_hat)\n",
    "        \n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f'At epoch {e+1}, training loss: {train_loss:.4f}, validation loss: {valid_loss:.4f}.')\n",
    "            \n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbc4a98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c7c31376504badb5e791172aea6a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 1, training loss: 1.3912, validation loss: 1.3880.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5752f8ed9b4008943d58996c7eed2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 2, training loss: 1.3840, validation loss: 1.3841.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e07ef4a247c41d79ce0c5305c017931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 3, training loss: 1.3793, validation loss: 1.3757.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1058ffaccc4e8294611b5f98ea6bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 4, training loss: 1.3745, validation loss: 1.3707.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf4746e31234b4fa7057647a610d133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 5, training loss: 1.3691, validation loss: 1.3711.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57da9c6798d427fae9c4045c0c04450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 6, training loss: 1.3637, validation loss: 1.3588.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae4e241e4064c7997081e59e9c83d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 7, training loss: 1.3578, validation loss: 1.3550.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c392d227924d14861c0f7dc9f574c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 8, training loss: 1.3512, validation loss: 1.3466.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29215a48e33457984b91352a8f8202f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 9, training loss: 1.3441, validation loss: 1.3389.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaa150a72b34a55a2704ebecb50ce48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 10, training loss: 1.3362, validation loss: 1.3325.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcb35c041c3444587b9b4515dc1054b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 11, training loss: 1.3271, validation loss: 1.3246.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d067828e673143019258fa29bca1cf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 12, training loss: 1.3168, validation loss: 1.3135.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa473ace0c74b788f3bcf0f7f509aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 13, training loss: 1.3051, validation loss: 1.2988.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf939f9e04541d4bca87d4c8f268df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 14, training loss: 1.2922, validation loss: 1.2842.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95237face95d40719acf5ed457b3d405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 15, training loss: 1.2776, validation loss: 1.2730.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4834c3c86b48416fa61008eeef0c1e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 16, training loss: 1.2615, validation loss: 1.2520.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f8163372d44197a7c0e7a32c38b678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 17, training loss: 1.2433, validation loss: 1.2349.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7833c9c62503459182a35de0de08be4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 18, training loss: 1.2230, validation loss: 1.2135.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714adb1128614e3b98015a485b8ead66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 19, training loss: 1.2009, validation loss: 1.1904.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49b76a5991d4e4cb732a50d6298765e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 20, training loss: 1.1769, validation loss: 1.1646.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44914a95207438ca2df24c62d9b7115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 21, training loss: 1.1508, validation loss: 1.1407.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2119e57e318a4a4cb63fb4424627786d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 22, training loss: 1.1232, validation loss: 1.1121.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e9a15f5b1642bc94f39465248e46c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 23, training loss: 1.0940, validation loss: 1.0818.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8a555ea975468d9aa5f41d1b76b103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 24, training loss: 1.0634, validation loss: 1.0498.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81757dc18e544dcfb4836976dedfb3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 25, training loss: 1.0323, validation loss: 1.0180.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c95417af1f943c5b4f66c08a43b0bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 26, training loss: 1.0003, validation loss: 0.9864.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092f44a8ad6e45f29747cbf55b4d9bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 27, training loss: 0.9684, validation loss: 0.9549.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72d851f1ec04b6682ddb19c092ce3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 28, training loss: 0.9364, validation loss: 0.9264.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e129d6d652f2407eae18e941731bec4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 29, training loss: 0.9052, validation loss: 0.8927.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8fd5d9c9e14eca9c8b924037e34655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 30, training loss: 0.8746, validation loss: 0.8625.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250d9c202ca04c028392148d240c34f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 31, training loss: 0.8454, validation loss: 0.8341.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8286a54e2b044f0cabe408c30a8a7fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 32, training loss: 0.8171, validation loss: 0.8077.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa00853ea5a843819ad5ee354a599932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 33, training loss: 0.7903, validation loss: 0.7809.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0f9950ec264bbbb3c0bbdb11f0efad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 34, training loss: 0.7648, validation loss: 0.7566.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4819e3947ee24c4ea3dbbf086908da70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 35, training loss: 0.7410, validation loss: 0.7340.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cf1dcf7ee94870baecbfd640db768a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 36, training loss: 0.7185, validation loss: 0.7121.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95105469a7148749f3a48c138f47bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 37, training loss: 0.6975, validation loss: 0.6964.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5442b90b13844f41beab90a389554094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 38, training loss: 0.6778, validation loss: 0.6733.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6715c5ed66ed491784e81dafee24a55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 39, training loss: 0.6596, validation loss: 0.6562.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bf0d0fa841428cad3bec45b7bd5238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 40, training loss: 0.6426, validation loss: 0.6416.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33705feeee8487c9e892b70241cdab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 41, training loss: 0.6268, validation loss: 0.6258.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba163c3477c14a928c244de237015dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 42, training loss: 0.6122, validation loss: 0.6123.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc8ae3f3ec3461f97cba60f71b75670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 43, training loss: 0.5984, validation loss: 0.5980.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2c1c8045c5440d8116e53767f385f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 44, training loss: 0.5858, validation loss: 0.5874.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58aecfc7a4374ac1bedbd773f625dc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 45, training loss: 0.5740, validation loss: 0.5753.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1287fb09bd143688809419d74b1c93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 46, training loss: 0.5631, validation loss: 0.5649.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b05e71e3f64bd49462a8f972aa3d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 47, training loss: 0.5528, validation loss: 0.5557.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17015cae49534e1bbba6743a572bb196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 48, training loss: 0.5433, validation loss: 0.5466.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bfd3b1a50e497fa4b954d903b3dd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 49, training loss: 0.5344, validation loss: 0.5398.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f8ccb62b5145fb8397d753a2b32605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 50, training loss: 0.5260, validation loss: 0.5333.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ebc6de61464f83aac580e329dbdf32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 51, training loss: 0.5183, validation loss: 0.5237.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c0f6950a954959b9f5fa349df466ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 52, training loss: 0.5109, validation loss: 0.5174.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92c6104766243c38eea71712dbb0d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 53, training loss: 0.5041, validation loss: 0.5105.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5db14c467d4e87bb5ac8d59b38fb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 54, training loss: 0.4976, validation loss: 0.5041.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ff29320fa84ecd9524f30e17c5ec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 55, training loss: 0.4915, validation loss: 0.4988.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6354c45d46e049638fee99c5dbc7e128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 56, training loss: 0.4857, validation loss: 0.4943.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af12f42fdab24e25ab798e148692b193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 57/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 57, training loss: 0.4803, validation loss: 0.4887.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2308a6f159f474292a376f752506654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 58/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 58, training loss: 0.4751, validation loss: 0.4835.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35588e8e76b94fb4a01312cc04b7beb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 59, training loss: 0.4702, validation loss: 0.4799.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501913e954d34b35acf2cf90e4835c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 60/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 60, training loss: 0.4656, validation loss: 0.4772.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa728721062466d88d551771b9ae364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 61/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 61, training loss: 0.4611, validation loss: 0.4719.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f663c625ca4057a2e6f4eb65769b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 62, training loss: 0.4569, validation loss: 0.4672.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6519b1b026fd4e0d9d0402bb89910a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 63, training loss: 0.4528, validation loss: 0.4641.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784c684f5b464a01be7a0b6982f72576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 64, training loss: 0.4490, validation loss: 0.4601.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d83945139d435898576e51372461b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 65/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 65, training loss: 0.4453, validation loss: 0.4569.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6391f4fcb9404b85ba76b03dd6f1266d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 66/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 66, training loss: 0.4419, validation loss: 0.4535.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5af26afd564fc3b60a2de91836d2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 67/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 67, training loss: 0.4384, validation loss: 0.4508.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50337e152796435c883b335d3e8b8543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 68/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 68, training loss: 0.4352, validation loss: 0.4481.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc4014a7ead4e7bade407184677ee1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 69/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 69, training loss: 0.4321, validation loss: 0.4456.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb02acada1b24b39b37e9d24b301ab1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 70/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 70, training loss: 0.4291, validation loss: 0.4435.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d1efffe10b494aa7157a5264f52d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 71/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 71, training loss: 0.4263, validation loss: 0.4401.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000acafdb25d4b01a3bc06b12d8d6f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 72/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 72, training loss: 0.4234, validation loss: 0.4373.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bbe152d62a4c24a2f70d2fe81251ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 73/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 73, training loss: 0.4207, validation loss: 0.4352.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e51e5af577b47d9a3093833559c6bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 74/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 74, training loss: 0.4182, validation loss: 0.4332.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c576282dbb549f59f21fb94b30ae893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 75/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 75, training loss: 0.4156, validation loss: 0.4308.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a927ad88357c4fbaaf27b8351194fe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 76/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 76, training loss: 0.4133, validation loss: 0.4289.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df455898fccd44df94775e9a1f9aa7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 77/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 77, training loss: 0.4108, validation loss: 0.4269.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f10d4a35f94701a57faa6f3813da44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 78/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 78, training loss: 0.4085, validation loss: 0.4248.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9ebaf8ea8b48a5a79037ff52885ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 79/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 79, training loss: 0.4063, validation loss: 0.4228.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a61bbacae9e4d319a31587d14b82e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 80/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 80, training loss: 0.4042, validation loss: 0.4228.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b40b4fe6e64563b8a6117662153d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 81/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 81, training loss: 0.4021, validation loss: 0.4196.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4ba68c2f5f4d088a1aab7034ef4443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 82/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 82, training loss: 0.4001, validation loss: 0.4182.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cb5be1f36e4772aad89c9266563e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 83/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 83, training loss: 0.3981, validation loss: 0.4161.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a71b102204944939ea5e23cd0b90eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 84/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 84, training loss: 0.3962, validation loss: 0.4146.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52607bb7196a4c988dfcb4b3dcbdd313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 85/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 85, training loss: 0.3943, validation loss: 0.4136.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0218952da443da88c59d5ba95c2280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 86/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 86, training loss: 0.3926, validation loss: 0.4114.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd16552642f425fbd41e1d19b06bced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 87/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 87, training loss: 0.3909, validation loss: 0.4110.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0ed1a085084d9dbcc1706aa61500b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 88/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 88, training loss: 0.3891, validation loss: 0.4088.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60015b3508e84dc4900830679702ca2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 89/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 89, training loss: 0.3874, validation loss: 0.4071.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c58b50d9164c0c874424407f8d81a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 90/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 90, training loss: 0.3858, validation loss: 0.4059.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a995b2831445a0abaaa44110e66671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 91/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 91, training loss: 0.3841, validation loss: 0.4048.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265d9a5f926546a0a692478cf035c941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 92/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 92, training loss: 0.3824, validation loss: 0.4033.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e486824590c44fe934b8f2c49c1267f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 93/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 93, training loss: 0.3810, validation loss: 0.4019.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85aaf94f80c545efbfb21181430ddd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 94/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 94, training loss: 0.3795, validation loss: 0.4018.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51c5714e51c483ca3832d6293f04783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 95/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 95, training loss: 0.3780, validation loss: 0.4002.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1f5c08d32443068d800b94e08e2466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 96/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 96, training loss: 0.3766, validation loss: 0.3982.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a185319d394947a83c6f27a6af00fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 97/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 97, training loss: 0.3752, validation loss: 0.3977.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd194f351114269ae4495bd5936d841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 98/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 98, training loss: 0.3738, validation loss: 0.3963.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c155727a0744981af82d56b4f243168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 99/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 99, training loss: 0.3725, validation loss: 0.3951.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfdba0e2ac64c55bac80f2ffe1dff01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 100/100:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 100, training loss: 0.3711, validation loss: 0.3940.\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "hidden_size = 50\n",
    "\n",
    "model = MLP(vocab_size, hidden_size, num_class)\n",
    "train_losses, valid_losses = optimization(model, x_train, y_train, lr, batch_size=batch_size, num_epoch=num_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54426c1b",
   "metadata": {},
   "source": [
    "#### 1.2.3 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd2b977a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7600,)\n",
      "MLP\n",
      "\n",
      "  Precision:\n",
      "    class 0: 0.8797, class 1: 0.9303, class 2: 0.8289, class 3: 0.8395\n",
      "\n",
      "  Recall:\n",
      "    class 0: 0.8774, class 1: 0.9479, class 2: 0.8289, class 3: 0.8258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_hat, _ = model.forward(x_test)\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(y_true.shape)\n",
    "precision = precision_score(y_true, y_hat, average=None)\n",
    "recall = recall_score(y_true, y_hat, average=None)\n",
    "\n",
    "print('MLP')\n",
    "print()\n",
    "print('  Precision:')\n",
    "print(f'    class {0}: {precision[0]:.4f}, class {1}: {precision[1]:.4f}, class {2}: {precision[2]:.4f}, class {3}: {precision[3]:.4f}')\n",
    "print()\n",
    "print('  Recall:')\n",
    "print(f'    class {0}: {recall[0]:.4f}, class {1}: {recall[1]:.4f}, class {2}: {recall[2]:.4f}, class {3}: {recall[3]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d201a3b",
   "metadata": {},
   "source": [
    "#### Run the following cell to plot the training loss and validation loss against epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ef556f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.plot(range(num_epoch), train_losses, valid_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend([\"Training loss\", \"Validation loss\"])\n",
    "plt.title('SGD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410018b",
   "metadata": {},
   "source": [
    "## 2. Word Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a2ffe1",
   "metadata": {},
   "source": [
    "#### 2.2.1 Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8846f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    ''' Compute the sigmoid function.\n",
    "        Inputs:\n",
    "            x: A scalar or numpy array\n",
    "        Outputs:\n",
    "            s: sigmoid(x)\n",
    "    '''\n",
    "    s = 0.\n",
    "    \n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    ''' Compute the softmax function for each row of the input x. \n",
    "        It is crucial that this function is optimized for speed \n",
    "        because it will be used frequently in later code. \n",
    "\n",
    "        Inputs:\n",
    "        x: A D dimensional vector or N x D dimensional numpy matrix.\n",
    "        Outputs:\n",
    "        x: You are allowed to modify x in-place\n",
    "    '''\n",
    "    if len(x.shape) == 1:\n",
    "        x = x - np.max(x)\n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "    else:\n",
    "        x = x - np.max(x, axis=1).reshape(-1, 1)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1).reshape(-1, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c83b0",
   "metadata": {},
   "source": [
    "#### 2.2.2 Word2Vec models with Stochastic gradient descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f919502",
   "metadata": {},
   "source": [
    "#### Naive Softmax loss & gradient function for word2vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d673c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveSoftmaxLossAndGradient(centerWordVec, outsideWordIdx, outsideVectors, dataset):\n",
    "    ''' Implement tha naive softmax loss and gradients between a center word's embedding \n",
    "        and an outside word's embedding. This will be the building block for our word2vec\n",
    "        models.\n",
    "        \n",
    "        Inputs:\n",
    "            centerWordVec: numpy ndarray, center word's embedding (v_c in question 2.1.1).\n",
    "            outsideWordIdx: integer, the index of the outside word (o of u_o in question 2.1.1).\n",
    "            outsideVectors: outside vectors (rows of matrix) for all words in vocab (U in question 2.1.1).\n",
    "            dataset: for negative sampling, ignore this argument in this function.\n",
    "        \n",
    "        Outputs:\n",
    "            loss: naive softmax loss\n",
    "            gradCenterVec: the gradient with respect to the center word vector (dJ/dv_c in question 2.1.1).\n",
    "            gradOutsideVecs: the gradient with respect to all the outside word vectors (dJ / dU).\n",
    "    '''\n",
    "    \n",
    "    y_hat = softmax(np.dot(outsideVectors,centerWordVec))\n",
    "    loss = -np.log(y_hat[outsideWordIdx])\n",
    "    y_hat[outsideWordIdx] -= 1.0\n",
    "    gradCenterVec = np.dot(outsideVectors.T,y_hat)\n",
    "    gradOutsideVecs = np.outer(y_hat,centerWordVec)\n",
    "        \n",
    "    return loss, gradCenterVec, gradOutsideVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a52976",
   "metadata": {},
   "source": [
    "#### Negative sampling loss function for word2vec models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb299791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegativeSamples(outsideWordIdx, dataset, K):\n",
    "    \"\"\" Samples K indexes which are not the outsideWordIdx \"\"\"\n",
    "\n",
    "    negSampleWordIndices = [None] * K\n",
    "    for k in range(K):\n",
    "        newidx = dataset.sampleTokenIdx()\n",
    "        while newidx == outsideWordIdx:\n",
    "            newidx = dataset.sampleTokenIdx()\n",
    "        negSampleWordIndices[k] = newidx\n",
    "    return negSampleWordIndices\n",
    "\n",
    "def negSamplingLossAndGradient(centerWordVec, outsideWordIdx, outsideVectors, dataset, K=10):\n",
    "    ''' Implement the negative sampling loss and gradients for a centerWordVec\n",
    "        and a outsideWordIdx word vector as a building block for word2vec\n",
    "        models. K is the number of negative samples to take.\n",
    "\n",
    "        Inputs/Outpus Specifications: same as naiveSoftmaxLossAndGradient\n",
    "    '''\n",
    "    \n",
    "    negSampleWordIndices = getNegativeSamples(outsideWordIdx, dataset, K)\n",
    "    indices = [outsideWordIdx] + negSampleWordIndices\n",
    "    \n",
    "    \n",
    "    gradCenterVec, gradOutsideVecs = np.zeros(centerWordVec.shape),np.zeros(outsideVectors.shape)\n",
    "    \n",
    "    y_hat = sigmoid(np.dot(outsideVectors[outsideWordIdx],centerWordVec))\n",
    "    loss = -np.log(y_hat)\n",
    "    gradCenterVec += outsideVectors[outsideWordIdx] * (y_hat - 1.0)\n",
    "    gradOutsideVecs[outsideWordIdx] = centerWordVec * (y_hat - 1.0)\n",
    "    \n",
    "    for i in range(K):\n",
    "        y_hat = sigmoid(-np.dot(outsideVectors[indices[i+1]],centerWordVec))\n",
    "        loss -= np.log(y_hat)\n",
    "        gradCenterVec += outsideVectors[indices[i+1]] * (1.0 - y_hat)\n",
    "        gradOutsideVecs[indices[i+1]] += centerWordVec * (1.0 - y_hat)\n",
    "    \n",
    "    \n",
    "    return loss, gradCenterVec, gradOutsideVecs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deb5b44",
   "metadata": {},
   "source": [
    "#### Skip-gram model in word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08f16e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram(currentCenterWord, windowSize, outsideWords, word2Ind,\n",
    "             centerWordVectors, outsideVectors, dataset,\n",
    "             word2vecLossAndGradient=naiveSoftmaxLossAndGradient):\n",
    "    ''' Implement the skip-gram model in this function.\n",
    "    \n",
    "        Inputs:\n",
    "            currentCenterWord: a string of the current center word\n",
    "            windowSize: integer, context window size\n",
    "            outsideWords: list of no more than 2*windowSize strings, the outside words\n",
    "            word2Ind: a dictionary that maps words to their indices in\n",
    "                      the word vector list\n",
    "            centerWordVectors: center word vectors (as rows) for all words in vocab\n",
    "                                (V in pdf handout)\n",
    "            outsideVectors: outside word vectors (as rows) for all words in vocab\n",
    "                            (U in pdf handout)\n",
    "            word2vecLossAndGradient: the loss and gradient function for\n",
    "                                       a prediction vector given the outsideWordIdx\n",
    "                                       word vectors, could be one of the two\n",
    "                                       loss functions you implemented above.\n",
    "\n",
    "        Outputs:\n",
    "            loss: the loss function value for the skip-gram model\n",
    "                    (J in the pdf handout)\n",
    "            gradCenterVecs: the gradient with respect to the center word vectors\n",
    "                    (dJ / dV in the pdf handout)\n",
    "            gradOutsideVectors: the gradient with respect to the outside word vectors\n",
    "                                (dJ / dU in the pdf handout)\n",
    "    '''\n",
    "    \n",
    "    loss = 0.0\n",
    "    gradCenterVecs = np.zeros(centerWordVectors.shape)\n",
    "    gradOutsideVectors = np.zeros(outsideVectors.shape)\n",
    "\n",
    "    i = word2Ind[currentCenterWord]\n",
    "    centerWordVec = centerWordVectors[i]\n",
    "    \n",
    "    for ow in outsideWords:\n",
    "        j = word2Ind[ow]\n",
    "        ls, cnt_grad, out_grad = word2vecLossAndGradient(centerWordVec, j, outsideVectors, dataset)\n",
    "        loss += ls\n",
    "        gradCenterVecs[i] += cnt_grad\n",
    "        gradOutsideVectors += out_grad\n",
    "\n",
    "\n",
    "\n",
    "    return loss, gradCenterVecs, gradOutsideVectors\n",
    "\n",
    "\n",
    "\n",
    "def normalizeRows(x):\n",
    "    \"\"\" Row normalization function\n",
    "    \"\"\"\n",
    "    N = x.shape[0]\n",
    "    x /= np.sqrt(np.sum(x**2, axis=1)).reshape((N, 1)) + 1e-30\n",
    "    return x\n",
    "\n",
    "\n",
    "def word2vec_sgd_wrapper(word2vecModel, word2Ind, wordVectors, dataset,\n",
    "                         windowSize,\n",
    "                         word2vecLossAndGradient=naiveSoftmaxLossAndGradient):\n",
    "    batchsize = 50\n",
    "    loss = 0.0\n",
    "    grad = np.zeros(wordVectors.shape)\n",
    "    N = wordVectors.shape[0]\n",
    "    centerWordVectors = wordVectors[:int(N/2), :]\n",
    "    outsideVectors = wordVectors[int(N/2):, :]\n",
    "    for i in range(batchsize):\n",
    "        windowSize1 = random.randint(1, windowSize)\n",
    "        centerWord, context = dataset.getRandomContext(windowSize1)\n",
    "\n",
    "        c, gin, gout = word2vecModel(\n",
    "            centerWord, windowSize1, context, word2Ind, centerWordVectors,\n",
    "            outsideVectors, dataset, word2vecLossAndGradient\n",
    "        )\n",
    "        loss += c / batchsize\n",
    "        grad[:int(N/2), :] += gin / batchsize\n",
    "        grad[int(N/2):, :] += gout / batchsize\n",
    "\n",
    "    return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d533fff",
   "metadata": {},
   "source": [
    "#### 2.2.3 K-nearest neighbors. (Fill the code: 10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "999a98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similartiy(v1, v2):\n",
    "    ''' return the cosine similarity of two vectors\n",
    "        \n",
    "        Inputs:\n",
    "            v1: a numpy ndarray\n",
    "            v2: a numpy ndarray\n",
    "        Outputs:\n",
    "            s: the cosine similarity of v1 and v2\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    s = np.dot(v1,v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    \n",
    "    \n",
    "    return s\n",
    "\n",
    "def knn(vec, mat, k):\n",
    "    ''' \n",
    "        Inputs:\n",
    "            vec: numpy ndarray, the target vector\n",
    "            mat: numpy ndarray, a matrix contains all the vectors (each row is a vector)\n",
    "            k: the number of the nearest neighbors you want to find.\n",
    "            \n",
    "        Outputs:\n",
    "            indices: the k indices of the matrix's rows that are closest to the vec\n",
    "    '''\n",
    "                          \n",
    "                          \n",
    "    scores = np.array([cosine_similartiy(vec, v2) for v2 in mat])\n",
    "    indices = (-scores).argsort()[:k]        \n",
    "    \n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f970e178",
   "metadata": {},
   "source": [
    "#### 2.2.4 Evaluation of the model with visualization and knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "09800ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "from utils.treebank import StanfordSentiment\n",
    "\n",
    "SAVE_PARAMS_EVERY = 5000\n",
    "\n",
    "\n",
    "def load_saved_params():\n",
    "    \"\"\"\n",
    "    A helper function that loads previously saved parameters and resets\n",
    "    iteration start.\n",
    "    \"\"\"\n",
    "    st = 0\n",
    "    for f in glob.glob(\"saved_params_*.npy\"):\n",
    "        iter = int(op.splitext(op.basename(f))[0].split(\"_\")[2])\n",
    "        if (iter > st):\n",
    "            st = iter\n",
    "\n",
    "    if st > 0:\n",
    "        params_file = \"saved_params_%d.npy\" % st\n",
    "        state_file = \"saved_state_%d.pickle\" % st\n",
    "        params = np.load(params_file)\n",
    "        with open(state_file, \"rb\") as f:\n",
    "            state = pickle.load(f)\n",
    "        return st, params, state\n",
    "    else:\n",
    "        return st, None, None\n",
    "\n",
    "\n",
    "def save_params(iter, params):\n",
    "    params_file = \"saved_params_%d.npy\" % iter\n",
    "    np.save(params_file, params)\n",
    "    with open(\"saved_state_%d.pickle\" % iter, \"wb\") as f:\n",
    "        pickle.dump(random.getstate(), f)\n",
    "\n",
    "\n",
    "def sgd(f, x0, step, iterations, postprocessing=None, useSaved=False,\n",
    "        PRINT_EVERY=1000):\n",
    "    \"\"\" Stochastic Gradient Descent\n",
    "\n",
    "    Arguments:\n",
    "    f -- the function to optimize, it should take a single\n",
    "         argument and yield two outputs, a loss and the gradient\n",
    "         with respect to the arguments\n",
    "    x0 -- the initial point to start SGD from\n",
    "    step -- the step size for SGD\n",
    "    iterations -- total iterations to run SGD for\n",
    "    postprocessing -- postprocessing function for the parameters\n",
    "                      if necessary. In the case of word2vec we will need to\n",
    "                      normalize the word vectors to have unit length.\n",
    "    PRINT_EVERY -- specifies how many iterations to output loss\n",
    "\n",
    "    Return:\n",
    "    x -- the parameter value after SGD finishes\n",
    "    \"\"\"\n",
    "\n",
    "    # Anneal learning rate every several iterations\n",
    "    ANNEAL_EVERY = 20000\n",
    "\n",
    "    if useSaved:\n",
    "        start_iter, oldx, state = load_saved_params()\n",
    "        if start_iter > 0:\n",
    "            x0 = oldx\n",
    "            step *= 0.5 ** (start_iter / ANNEAL_EVERY)\n",
    "\n",
    "        if state:\n",
    "            random.setstate(state)\n",
    "    else:\n",
    "        start_iter = 0\n",
    "\n",
    "    x = x0\n",
    "\n",
    "    if not postprocessing:\n",
    "        def postprocessing(x): return x\n",
    "\n",
    "    exploss = None\n",
    "\n",
    "    last_time = time.time()\n",
    "    for iter in range(start_iter + 1, iterations + 1):\n",
    "\n",
    "        loss = None\n",
    "        loss, g = f(x)\n",
    "        x -= step * g\n",
    "\n",
    "        x = postprocessing(x)\n",
    "        if iter % PRINT_EVERY == 0:\n",
    "            if not exploss:\n",
    "                exploss = loss\n",
    "            else:\n",
    "                exploss = .95 * exploss + .05 * loss\n",
    "            print(\"iter %d: %f, duration %d\" % (iter, exploss, int(time.time() - last_time)))\n",
    "            last_time = time.time()\n",
    "\n",
    "        if iter % SAVE_PARAMS_EVERY == 0 and useSaved:\n",
    "            save_params(iter, x)\n",
    "\n",
    "        if iter % ANNEAL_EVERY == 0:\n",
    "            step *= 0.5\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af9dc5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3fcb1697ec4c2ab07da5356d7fbb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 100: 26.533652, duration 7\n",
      "iter 200: 26.442153, duration 4\n",
      "iter 300: 26.362852, duration 4\n",
      "iter 400: 26.379029, duration 4\n",
      "iter 500: 26.645997, duration 4\n",
      "iter 600: 26.556476, duration 4\n",
      "iter 700: 26.494382, duration 4\n",
      "iter 800: 26.267603, duration 4\n",
      "iter 900: 26.166555, duration 4\n",
      "iter 1000: 26.139140, duration 4\n",
      "iter 1100: 26.143564, duration 4\n",
      "iter 1200: 26.140144, duration 4\n",
      "iter 1300: 26.144551, duration 5\n",
      "iter 1400: 26.133381, duration 5\n",
      "iter 1500: 26.099830, duration 4\n",
      "iter 1600: 25.984087, duration 4\n",
      "iter 1700: 25.973000, duration 5\n",
      "iter 1800: 25.832863, duration 4\n",
      "iter 1900: 25.706221, duration 3\n",
      "iter 2000: 25.661754, duration 3\n",
      "iter 2100: 25.658153, duration 3\n",
      "iter 2200: 25.593158, duration 4\n",
      "iter 2300: 25.559810, duration 3\n",
      "iter 2400: 25.474018, duration 3\n",
      "iter 2500: 25.276726, duration 3\n",
      "iter 2600: 25.431643, duration 4\n",
      "iter 2700: 25.358022, duration 4\n",
      "iter 2800: 25.357574, duration 4\n",
      "iter 2900: 25.299071, duration 4\n",
      "iter 3000: 25.262539, duration 4\n",
      "iter 3100: 25.135412, duration 4\n",
      "iter 3200: 25.082187, duration 4\n",
      "iter 3300: 25.129134, duration 3\n",
      "iter 3400: 25.105795, duration 4\n",
      "iter 3500: 25.191991, duration 4\n",
      "iter 3600: 25.019248, duration 4\n",
      "iter 3700: 24.877977, duration 4\n",
      "iter 3800: 24.966022, duration 3\n",
      "iter 3900: 24.942717, duration 3\n",
      "iter 4000: 25.048197, duration 3\n",
      "iter 4100: 24.974736, duration 3\n",
      "iter 4200: 24.794106, duration 4\n",
      "iter 4300: 24.679391, duration 4\n",
      "iter 4400: 24.475788, duration 4\n",
      "iter 4500: 24.503399, duration 3\n",
      "iter 4600: 24.412142, duration 4\n",
      "iter 4700: 24.372499, duration 5\n",
      "iter 4800: 24.340971, duration 5\n",
      "iter 4900: 24.285215, duration 4\n",
      "iter 5000: 24.116299, duration 4\n",
      "iter 5100: 23.917895, duration 4\n",
      "iter 5200: 23.697717, duration 4\n",
      "iter 5300: 23.578542, duration 3\n",
      "iter 5400: 23.356738, duration 3\n",
      "iter 5500: 23.195149, duration 3\n",
      "iter 5600: 22.975032, duration 3\n",
      "iter 5700: 22.719515, duration 3\n",
      "iter 5800: 22.566243, duration 3\n",
      "iter 5900: 22.390603, duration 3\n",
      "iter 6000: 22.305101, duration 4\n",
      "iter 6100: 22.270860, duration 4\n",
      "iter 6200: 22.122517, duration 5\n",
      "iter 6300: 22.019875, duration 4\n",
      "iter 6400: 21.730558, duration 4\n",
      "iter 6500: 21.563129, duration 4\n",
      "iter 6600: 21.377811, duration 5\n",
      "iter 6700: 21.304233, duration 5\n",
      "iter 6800: 21.061128, duration 4\n",
      "iter 6900: 20.777093, duration 4\n",
      "iter 7000: 20.578965, duration 4\n",
      "iter 7100: 20.445404, duration 4\n",
      "iter 7200: 20.292106, duration 4\n",
      "iter 7300: 20.169572, duration 4\n",
      "iter 7400: 20.113234, duration 4\n",
      "iter 7500: 19.921253, duration 3\n",
      "iter 7600: 19.685007, duration 4\n",
      "iter 7700: 19.574197, duration 4\n",
      "iter 7800: 19.368772, duration 4\n",
      "iter 7900: 19.143314, duration 4\n",
      "iter 8000: 18.995712, duration 4\n",
      "iter 8100: 18.688525, duration 4\n",
      "iter 8200: 18.544797, duration 4\n",
      "iter 8300: 18.408872, duration 4\n",
      "iter 8400: 18.290109, duration 5\n",
      "iter 8500: 18.272098, duration 4\n",
      "iter 8600: 18.047579, duration 3\n",
      "iter 8700: 18.121159, duration 3\n",
      "iter 8800: 18.056486, duration 3\n",
      "iter 8900: 17.885317, duration 3\n",
      "iter 9000: 17.776422, duration 3\n",
      "iter 9100: 17.690539, duration 3\n",
      "iter 9200: 17.700911, duration 3\n",
      "iter 9300: 17.467785, duration 3\n",
      "iter 9400: 17.375570, duration 3\n",
      "iter 9500: 17.277564, duration 3\n",
      "iter 9600: 17.133869, duration 3\n",
      "iter 9700: 17.059698, duration 3\n",
      "iter 9800: 16.934664, duration 5\n",
      "iter 9900: 16.732717, duration 5\n",
      "iter 10000: 16.581679, duration 4\n",
      "iter 10100: 16.530837, duration 3\n",
      "iter 10200: 16.356175, duration 4\n",
      "iter 10300: 16.242540, duration 4\n",
      "iter 10400: 16.252027, duration 3\n",
      "iter 10500: 16.065785, duration 4\n",
      "iter 10600: 15.992410, duration 4\n",
      "iter 10700: 15.844003, duration 3\n",
      "iter 10800: 15.798076, duration 3\n",
      "iter 10900: 15.702490, duration 4\n",
      "iter 11000: 15.726728, duration 4\n",
      "iter 11100: 15.712400, duration 3\n",
      "iter 11200: 15.600286, duration 3\n",
      "iter 11300: 15.617794, duration 4\n",
      "iter 11400: 15.493313, duration 4\n",
      "iter 11500: 15.386010, duration 3\n",
      "iter 11600: 15.345569, duration 3\n",
      "iter 11700: 15.245014, duration 3\n",
      "iter 11800: 15.127812, duration 3\n",
      "iter 11900: 14.971225, duration 3\n",
      "iter 12000: 14.973109, duration 4\n",
      "iter 12100: 14.888509, duration 4\n",
      "iter 12200: 14.762312, duration 4\n",
      "iter 12300: 14.689420, duration 3\n",
      "iter 12400: 14.525046, duration 3\n",
      "iter 12500: 14.459266, duration 4\n",
      "iter 12600: 14.441864, duration 4\n",
      "iter 12700: 14.431429, duration 4\n",
      "iter 12800: 14.372607, duration 3\n",
      "iter 12900: 14.404222, duration 3\n",
      "iter 13000: 14.306994, duration 3\n",
      "iter 13100: 14.234126, duration 3\n",
      "iter 13200: 14.164251, duration 3\n",
      "iter 13300: 14.131341, duration 3\n",
      "iter 13400: 14.184623, duration 3\n",
      "iter 13500: 14.147464, duration 3\n",
      "iter 13600: 14.062300, duration 4\n",
      "iter 13700: 13.982362, duration 4\n",
      "iter 13800: 14.030801, duration 3\n",
      "iter 13900: 13.931318, duration 3\n",
      "iter 14000: 13.826314, duration 4\n",
      "iter 14100: 13.914295, duration 3\n",
      "iter 14200: 13.871857, duration 4\n",
      "iter 14300: 13.809134, duration 3\n",
      "iter 14400: 13.787380, duration 3\n",
      "iter 14500: 13.781654, duration 4\n",
      "iter 14600: 13.705596, duration 4\n",
      "iter 14700: 13.571165, duration 3\n",
      "iter 14800: 13.500257, duration 4\n",
      "iter 14900: 13.495811, duration 3\n",
      "iter 15000: 13.386111, duration 4\n",
      "iter 15100: 13.435750, duration 3\n",
      "iter 15200: 13.452280, duration 4\n",
      "iter 15300: 13.378375, duration 4\n",
      "iter 15400: 13.287675, duration 4\n",
      "iter 15500: 13.257684, duration 4\n",
      "iter 15600: 13.214975, duration 4\n",
      "iter 15700: 13.211190, duration 4\n",
      "iter 15800: 13.195887, duration 3\n",
      "iter 15900: 13.171581, duration 3\n",
      "iter 16000: 13.101459, duration 4\n",
      "iter 16100: 13.118920, duration 3\n",
      "iter 16200: 13.138625, duration 4\n",
      "iter 16300: 13.057775, duration 3\n",
      "iter 16400: 13.008743, duration 3\n",
      "iter 16500: 12.977880, duration 3\n",
      "iter 16600: 12.949996, duration 4\n",
      "iter 16700: 12.880976, duration 3\n",
      "iter 16800: 12.852387, duration 4\n",
      "iter 16900: 12.896414, duration 4\n",
      "iter 17000: 12.822132, duration 3\n",
      "iter 17100: 12.758316, duration 3\n",
      "iter 17200: 12.805274, duration 4\n",
      "iter 17300: 12.785267, duration 3\n",
      "iter 17400: 12.706008, duration 4\n",
      "iter 17500: 12.628874, duration 4\n",
      "iter 17600: 12.637815, duration 3\n",
      "iter 17700: 12.633680, duration 4\n",
      "iter 17800: 12.571507, duration 4\n",
      "iter 17900: 12.518225, duration 3\n",
      "iter 18000: 12.562671, duration 4\n",
      "iter 18100: 12.595795, duration 3\n",
      "iter 18200: 12.576145, duration 3\n",
      "iter 18300: 12.586966, duration 3\n",
      "iter 18400: 12.604689, duration 4\n",
      "iter 18500: 12.591021, duration 4\n",
      "iter 18600: 12.558211, duration 3\n",
      "iter 18700: 12.564355, duration 4\n",
      "iter 18800: 12.484930, duration 3\n",
      "iter 18900: 12.386545, duration 4\n",
      "iter 19000: 12.299954, duration 4\n",
      "iter 19100: 12.314964, duration 3\n",
      "iter 19200: 12.248146, duration 3\n",
      "iter 19300: 12.146965, duration 3\n",
      "iter 19400: 12.199517, duration 3\n",
      "iter 19500: 12.211654, duration 3\n",
      "iter 19600: 12.184147, duration 3\n",
      "iter 19700: 12.201201, duration 3\n",
      "iter 19800: 12.143845, duration 4\n",
      "iter 19900: 12.105279, duration 4\n",
      "iter 20000: 12.004683, duration 3\n",
      "iter 20100: 12.052670, duration 3\n",
      "iter 20200: 12.032024, duration 3\n",
      "iter 20300: 12.031803, duration 4\n",
      "iter 20400: 12.079509, duration 3\n",
      "iter 20500: 12.076173, duration 4\n",
      "iter 20600: 12.080502, duration 4\n",
      "iter 20700: 12.128611, duration 3\n",
      "iter 20800: 12.082042, duration 4\n",
      "iter 20900: 12.074137, duration 4\n",
      "iter 21000: 12.027568, duration 4\n",
      "iter 21100: 12.003203, duration 4\n",
      "iter 21200: 11.948072, duration 4\n",
      "iter 21300: 11.997381, duration 3\n",
      "iter 21400: 11.907433, duration 3\n",
      "iter 21500: 11.906085, duration 3\n",
      "iter 21600: 11.883176, duration 3\n",
      "iter 21700: 11.886513, duration 4\n",
      "iter 21800: 11.847084, duration 4\n",
      "iter 21900: 11.878306, duration 4\n",
      "iter 22000: 11.877016, duration 4\n",
      "iter 22100: 11.887660, duration 4\n",
      "iter 22200: 11.917101, duration 4\n",
      "iter 22300: 11.904611, duration 4\n",
      "iter 22400: 11.936926, duration 4\n",
      "iter 22500: 11.952354, duration 4\n",
      "iter 22600: 11.971253, duration 4\n",
      "iter 22700: 12.015103, duration 4\n",
      "iter 22800: 12.085785, duration 3\n",
      "iter 22900: 12.151649, duration 4\n",
      "iter 23000: 12.194833, duration 4\n",
      "iter 23100: 12.148050, duration 4\n",
      "iter 23200: 12.083964, duration 4\n",
      "iter 23300: 12.109292, duration 3\n",
      "iter 23400: 12.062411, duration 3\n",
      "iter 23500: 12.143866, duration 3\n",
      "iter 23600: 12.029070, duration 4\n",
      "iter 23700: 11.982179, duration 4\n",
      "iter 23800: 11.873158, duration 4\n",
      "iter 23900: 11.926078, duration 4\n",
      "iter 24000: 11.903266, duration 3\n",
      "iter 24100: 11.826894, duration 4\n",
      "iter 24200: 11.742604, duration 3\n",
      "iter 24300: 11.755529, duration 4\n",
      "iter 24400: 11.753023, duration 3\n",
      "iter 24500: 11.727481, duration 3\n",
      "iter 24600: 11.744937, duration 4\n",
      "iter 24700: 11.626691, duration 4\n",
      "iter 24800: 11.665695, duration 4\n",
      "iter 24900: 11.610531, duration 4\n",
      "iter 25000: 11.490637, duration 3\n",
      "iter 25100: 11.621586, duration 3\n",
      "iter 25200: 11.652698, duration 3\n",
      "iter 25300: 11.698224, duration 4\n",
      "iter 25400: 11.623585, duration 3\n",
      "iter 25500: 11.686200, duration 3\n",
      "iter 25600: 11.664280, duration 4\n",
      "iter 25700: 11.582322, duration 3\n",
      "iter 25800: 11.546031, duration 4\n",
      "iter 25900: 11.575962, duration 3\n",
      "iter 26000: 11.599209, duration 4\n",
      "iter 26100: 11.571489, duration 4\n",
      "iter 26200: 11.559832, duration 4\n",
      "iter 26300: 11.535961, duration 3\n",
      "iter 26400: 11.533454, duration 4\n",
      "iter 26500: 11.549103, duration 4\n",
      "iter 26600: 11.515204, duration 3\n",
      "iter 26700: 11.551119, duration 3\n",
      "iter 26800: 11.538765, duration 4\n",
      "iter 26900: 11.685035, duration 4\n",
      "iter 27000: 11.675619, duration 3\n",
      "iter 27100: 11.659949, duration 4\n",
      "iter 27200: 11.713323, duration 4\n",
      "iter 27300: 11.649582, duration 3\n",
      "iter 27400: 11.691073, duration 3\n",
      "iter 27500: 11.685030, duration 4\n",
      "iter 27600: 11.665550, duration 4\n",
      "iter 27700: 11.685069, duration 4\n",
      "iter 27800: 11.644775, duration 3\n",
      "iter 27900: 11.615435, duration 3\n",
      "iter 28000: 11.619947, duration 4\n",
      "iter 28100: 11.555150, duration 3\n",
      "iter 28200: 11.575712, duration 4\n",
      "iter 28300: 11.581818, duration 3\n",
      "iter 28400: 11.593866, duration 4\n",
      "iter 28500: 11.573069, duration 4\n",
      "iter 28600: 11.552620, duration 3\n",
      "iter 28700: 11.580976, duration 4\n",
      "iter 28800: 11.574572, duration 4\n",
      "iter 28900: 11.682204, duration 4\n",
      "iter 29000: 11.762065, duration 4\n",
      "iter 29100: 11.762070, duration 4\n",
      "iter 29200: 11.695954, duration 3\n",
      "iter 29300: 11.667767, duration 3\n",
      "iter 29400: 11.661028, duration 3\n",
      "iter 29500: 11.632585, duration 3\n",
      "iter 29600: 11.621356, duration 4\n",
      "iter 29700: 11.702919, duration 4\n",
      "iter 29800: 11.705132, duration 4\n",
      "iter 29900: 11.727959, duration 3\n",
      "iter 30000: 11.684659, duration 3\n",
      "iter 30100: 11.687794, duration 4\n",
      "iter 30200: 11.761969, duration 3\n",
      "iter 30300: 11.726428, duration 3\n",
      "iter 30400: 11.693137, duration 4\n",
      "iter 30500: 11.726517, duration 3\n",
      "iter 30600: 11.705337, duration 3\n",
      "iter 30700: 11.749252, duration 3\n",
      "iter 30800: 11.780467, duration 3\n",
      "iter 30900: 11.703519, duration 3\n",
      "iter 31000: 11.738091, duration 3\n",
      "iter 31100: 11.709229, duration 3\n",
      "iter 31200: 11.703766, duration 4\n",
      "iter 31300: 11.705398, duration 3\n",
      "iter 31400: 11.702653, duration 3\n",
      "iter 31500: 11.671722, duration 3\n",
      "iter 31600: 11.623249, duration 3\n",
      "iter 31700: 11.660371, duration 4\n",
      "iter 31800: 11.621599, duration 3\n",
      "iter 31900: 11.523162, duration 3\n",
      "iter 32000: 11.452717, duration 3\n",
      "iter 32100: 11.342594, duration 3\n",
      "iter 32200: 11.360474, duration 3\n",
      "iter 32300: 11.421481, duration 4\n",
      "iter 32400: 11.385637, duration 4\n",
      "iter 32500: 11.362096, duration 4\n",
      "iter 32600: 11.341981, duration 4\n",
      "iter 32700: 11.282591, duration 3\n",
      "iter 32800: 11.342907, duration 4\n",
      "iter 32900: 11.403638, duration 4\n",
      "iter 33000: 11.497392, duration 3\n",
      "iter 33100: 11.522789, duration 3\n",
      "iter 33200: 11.555984, duration 3\n",
      "iter 33300: 11.563301, duration 3\n",
      "iter 33400: 11.519961, duration 3\n",
      "iter 33500: 11.582903, duration 4\n",
      "iter 33600: 11.549425, duration 3\n",
      "iter 33700: 11.524271, duration 3\n",
      "iter 33800: 11.486773, duration 3\n",
      "iter 33900: 11.461272, duration 4\n",
      "iter 34000: 11.415875, duration 3\n",
      "iter 34100: 11.347025, duration 3\n",
      "iter 34200: 11.354885, duration 4\n",
      "iter 34300: 11.359240, duration 3\n",
      "iter 34400: 11.409817, duration 3\n",
      "iter 34500: 11.437140, duration 4\n",
      "iter 34600: 11.429910, duration 4\n",
      "iter 34700: 11.399766, duration 4\n",
      "iter 34800: 11.449021, duration 4\n",
      "iter 34900: 11.452551, duration 3\n",
      "iter 35000: 11.488702, duration 4\n",
      "iter 35100: 11.534039, duration 4\n",
      "iter 35200: 11.469980, duration 4\n",
      "iter 35300: 11.492129, duration 3\n",
      "iter 35400: 11.511658, duration 4\n",
      "iter 35500: 11.427500, duration 3\n",
      "iter 35600: 11.327677, duration 4\n",
      "iter 35700: 11.307996, duration 4\n",
      "iter 35800: 11.339256, duration 4\n",
      "iter 35900: 11.297552, duration 3\n",
      "iter 36000: 11.268051, duration 4\n",
      "iter 36100: 11.261971, duration 3\n",
      "iter 36200: 11.282130, duration 3\n",
      "iter 36300: 11.292539, duration 3\n",
      "iter 36400: 11.325229, duration 3\n",
      "iter 36500: 11.386171, duration 3\n",
      "iter 36600: 11.408883, duration 4\n",
      "iter 36700: 11.450691, duration 3\n",
      "iter 36800: 11.490205, duration 4\n",
      "iter 36900: 11.477070, duration 3\n",
      "iter 37000: 11.354447, duration 4\n",
      "iter 37100: 11.406944, duration 4\n",
      "iter 37200: 11.391598, duration 4\n",
      "iter 37300: 11.417708, duration 3\n",
      "iter 37400: 11.401601, duration 3\n",
      "iter 37500: 11.377789, duration 3\n",
      "iter 37600: 11.390523, duration 4\n",
      "iter 37700: 11.369925, duration 3\n",
      "iter 37800: 11.332205, duration 3\n",
      "iter 37900: 11.305094, duration 4\n",
      "iter 38000: 11.319132, duration 3\n",
      "iter 38100: 11.405322, duration 4\n",
      "iter 38200: 11.474789, duration 4\n",
      "iter 38300: 11.494765, duration 3\n",
      "iter 38400: 11.467361, duration 3\n",
      "iter 38500: 11.446585, duration 3\n",
      "iter 38600: 11.443815, duration 3\n",
      "iter 38700: 11.362482, duration 4\n",
      "iter 38800: 11.345227, duration 3\n",
      "iter 38900: 11.269422, duration 3\n",
      "iter 39000: 11.303154, duration 3\n",
      "iter 39100: 11.381687, duration 3\n",
      "iter 39200: 11.449834, duration 3\n",
      "iter 39300: 11.509199, duration 4\n",
      "iter 39400: 11.466303, duration 4\n",
      "iter 39500: 11.440082, duration 3\n",
      "iter 39600: 11.451217, duration 4\n",
      "iter 39700: 11.395887, duration 3\n",
      "iter 39800: 11.376353, duration 4\n",
      "iter 39900: 11.378572, duration 3\n",
      "iter 40000: 11.341972, duration 3\n",
      "sanity check: cost at convergence should be around or below 10\n",
      "training took 1642 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils.treebank import StanfordSentiment\n",
    "\n",
    "random.seed(314)\n",
    "dataset = StanfordSentiment()\n",
    "tokens = dataset.tokens()\n",
    "nWords = len(tokens)\n",
    "\n",
    "\n",
    "dimVectors = 10\n",
    "\n",
    "# Context size\n",
    "C = 5\n",
    "\n",
    "# Reset the random seed to make sure that everyone gets the same results\n",
    "random.seed(31415)\n",
    "np.random.seed(9265)\n",
    "\n",
    "startTime = time.time()\n",
    "wordVectors = np.concatenate(\n",
    "    ((np.random.rand(nWords, dimVectors) - 0.5) /\n",
    "     dimVectors, np.zeros((nWords, dimVectors))),\n",
    "    axis=0)\n",
    "\n",
    "wordVectors = sgd(\n",
    "    lambda vec: word2vec_sgd_wrapper(skipgram, tokens, vec, dataset, C,\n",
    "                                     negSamplingLossAndGradient),\n",
    "    wordVectors, 0.3, 40000, None, True, PRINT_EVERY=100)\n",
    "\n",
    "print(\"sanity check: cost at convergence should be around or below 10\")\n",
    "print(\"training took %d seconds\" % (time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following cell to obtain the visulaization of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# concatenate the input and output word vectors\n",
    "wordVectors = np.concatenate(\n",
    "    (wordVectors[:nWords, :], wordVectors[nWords:, :]),\n",
    "    axis=0)\n",
    "\n",
    "visualizeWords = [\n",
    "    'state', 'season', 'company', 'world', 'against', \n",
    "    'president', 'game', 'million', 'oil', 'government'\n",
    "]\n",
    "\n",
    "visualizeIdx = [tokens[word] for word in visualizeWords]\n",
    "visualizeVecs = wordVectors[visualizeIdx, :]\n",
    "temp = (visualizeVecs - np.mean(visualizeVecs, axis=0))\n",
    "covariance = 1.0 / len(visualizeIdx) * temp.T.dot(temp)\n",
    "U, S, V = np.linalg.svd(covariance)\n",
    "coord = temp.dot(U[:, 0:2])\n",
    "\n",
    "for i in range(len(visualizeWords)):\n",
    "    plt.text(coord[i, 0], coord[i, 1], visualizeWords[i],\n",
    "             bbox=dict(facecolor='green', alpha=0.1))\n",
    "\n",
    "plt.xlim((np.min(coord[:, 0]), np.max(coord[:, 0])))\n",
    "plt.ylim((np.min(coord[:, 1]), np.max(coord[:, 1])))\n",
    "\n",
    "plt.savefig('word_vectors.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the following cell to obtain the k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: \"state\" is close to ['state', 'down', 'making', 'late', 'centrino', 'berth', 'released', 'chipmakers', 'we', 'major']\n",
      "Word: \"season\" is close to ['season', 'no', 'series', 'despite', 'strike', 'computer', 'notre', 'pence', 'months', 'services']\n",
      "Word: \"company\" is close to ['company', 'step', 'neitzel', 'sylvester', 'customer', 'you', 'guyler', 'tells', 'contrast', 'brisk']\n",
      "Word: \"world\" is close to ['world', 'saturday', 'ghz', 'karzai', 'late', 'sentenced', 'deliberations', 'bcn', 'business', 'instruments']\n",
      "Word: \"against\" is close to ['against', 'must', 'place', 'costs', 'another', 'primarily', 'certainty', 'cancun', 'annoying', 'rolled']\n",
      "Word: \"president\" is close to ['president', 'renegade', 'rican', 'myriad', 'door', 'tendering', 'founded', 'newton', 'democracy', 'flowers']\n",
      "Word: \"game\" is close to ['game', 'broke', 'loss', 'economy', 'appeared', 'guys', 'companies', 'spoornet', 'lions', 'carve']\n",
      "Word: \"million\" is close to ['million', 'penalties', 'rising', 'appreciation', 'fold', 'neglect', 'decline', 'been', 'posted', 'ambulance']\n",
      "Word: \"oil\" is close to ['oil', 'churns', 'beasts', 'jobs', 'labeled', 'research', 'importantly', 'election', 'analysts', 'nigeria']\n",
      "Word: \"government\" is close to ['government', 'businesses', 'mozilla', 'ethylene', 'bayley', 'gaven', 'plant', 'doom', 'confirmed', 'chain']\n"
     ]
    }
   ],
   "source": [
    "centerVectors = wordVectors[:nWords, :]\n",
    "outputVectors = wordVectors[nWords:, :]\n",
    "for word in visualizeWords:\n",
    "    idx = tokens[word]\n",
    "    vec = outputVectors[idx]\n",
    "    indices = knn(vec, outputVectors, 10)\n",
    "    closed_words = [list(tokens.keys())[i] for i in indices]\n",
    "    print('Word: \"{}\" is close to {}'.format(word, closed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
