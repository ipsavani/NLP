# NLP
Basics and Utility code for Natural Language Processing 

- Text Classification : 
  - Pre-Processing.
  - Tokenization.
  - Feature Extraction.
  - Logistic Regression.
  - Gradient Descent.
  - Evaluation.
  
- MLP and Word Vectors :
  - Pre-Processing and Multi-Layer Perceptron on Text Data.
  - Word2Vec models with stochastic grdient descent.
    - Naive softmax Loss/Negative Sampling Loss/Skip-Gram.
    - KNN for visualization.
    
- Language Models : 
  - N-gram Language model with Laplace smoothing, kneser-ney smoothing and goodturing smoothing.
  - Evaluation using perplexity.
  - RNN-based language model.
  
- SeqtoSeq Models : 
  - Implement sequence to sequence neural network using pytorch for machine translation.
  - Evaluation using BLEU score.
  
- Dependancy Parsing :
  - implementing a neural-network based dependency parser with the goal of maximizing performance on the UAS (Unlabeled Attachment Score) metric.
